{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import subprocess as sbp\n",
    "import pdb\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = psycopg2.connect(\"dbname='data_analytics' user='nagavenkat' host='localhost' password='Mindman@1988'\")\n",
    "except:\n",
    "    print \"I am unable to connect to the database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try:\n",
    "#     conn.close()\n",
    "# except:\n",
    "#     pass\n",
    "# try:\n",
    "#     conn = psycopg2.connect(\"dbname='data_analytics' user='nagavenkat' host='localhost' password='Mindman@1988'\")\n",
    "# except:\n",
    "#     print \"I am unable to connect to the database\"\n",
    "    \n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"\"\" USE data_analytics;\"\"\" )\n",
    "# cur.execute(\"\"\" SELECT * FROM \"Chicago_crime_2001_present\" LIMIT 10; \"\"\" )\n",
    "rows = cur.fetchall()\n",
    "print \"\\nShow me the databases:\\n\"\n",
    "for row in rows:\n",
    "    print \"   \", row[0]\n",
    "\n",
    "# cur.execute(\"\"\" SELECT * FROM \"Chicago_crime_2001_present\" LIMIT 10; \"\"\" )\n",
    "# rows = cur.fetchall()\n",
    "# print \"\\nShow me the databases:\\n\"\n",
    "# for row in rows:\n",
    "#     print \"   \", row[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://nagavenkat:Mindman@1988@localhost:5432/data_analytics')\n",
    "# df.to_sql('table_name', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname='chicago crime/Crimes_-_2001_to_present.csv'\n",
    "reader=pd.read_hdf('chicago crime/Crimes_-_2001_to_present_comp.h5',chunksize=50000)\n",
    "# cols={\n",
    "#     ID                       int64\n",
    "# Case Number   Crimes_-_2001_to_present_comp.h5           object\n",
    "# Date                     object\n",
    "# Block                    object\n",
    "# IUCR                     object\n",
    "# Primary Type             object\n",
    "# Description              object\n",
    "# Location Description     object\n",
    "# Arrest                     bool\n",
    "# Domestic                   bool\n",
    "# Beat                      int64\n",
    "# District                  int64\n",
    "# Ward                    float64\n",
    "# Community Area          float64\n",
    "# FBI Code                 object\n",
    "# X Coordinate            float64\n",
    "# Y Coordinate            float64\n",
    "# Year                    float64\n",
    "# Updated On               object\n",
    "    \n",
    "# 'Beat' :                     'int64',\n",
    "# 'District'     :             'int64',\n",
    "# 'Ward'         :           'float64',\n",
    "# 'Community Area' :         'float64',\n",
    "# 'X Coordinate'     :       'float64',\n",
    "# 'Y Coordinate'     :       'float64',\n",
    "# 'Year'              :      'float64',\n",
    "# 'Latitude'           :     'float64',\n",
    "# 'Longitude'           :    'float64',\n",
    "#      }\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('chicago_crime', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname='divvy_set_1/Divvy_historical.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('divvy_current', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname='divvy_set_1/Divvy_Trips.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('divvy_Trips', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname='german_credit/german_credit.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('german_credit', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname='business_lisences_chicago/Business_Licenses_-_Current_Active.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    df.fillna(value=-1,inplace=True)\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('chicago_business_license', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname='zip_codes_city_state_county.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    df.fillna(value=-1,inplace=True)\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('zipcodes', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname='gre_gpa/logistic_regression_gre_gpa_rank_admit.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    df.fillna(value=-1,inplace=True)\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('gre_gpa', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname='direct_lending_club_data/lending_club_data.h5'\n",
    "df=pd.read_hdf(fname,'loandict')\n",
    "df.to_sql('lending_club_dict', engine,flavor='mysql',if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'member_id', u'loan_amnt', u'funded_amnt', u'funded_amnt_inv',\n",
       "       u'term', u'int_rate', u'installment', u'grade', u'sub_grade',\n",
       "       u'emp_title', u'emp_length', u'home_ownership', u'annual_inc',\n",
       "       u'verification_status', u'issue_d', u'loan_status', u'pymnt_plan',\n",
       "       u'url', u'desc', u'purpose', u'title', u'zip_code', u'addr_state',\n",
       "       u'dti', u'delinq_2yrs', u'earliest_cr_line', u'inq_last_6mths',\n",
       "       u'mths_since_last_delinq', u'mths_since_last_record', u'open_acc',\n",
       "       u'pub_rec', u'revol_bal', u'revol_util', u'total_acc',\n",
       "       u'initial_list_status', u'out_prncp', u'out_prncp_inv', u'total_pymnt',\n",
       "       u'total_pymnt_inv', u'total_rec_prncp', u'total_rec_int',\n",
       "       u'total_rec_late_fee', u'recoveries', u'collection_recovery_fee',\n",
       "       u'last_pymnt_d', u'last_pymnt_amnt', u'next_pymnt_d',\n",
       "       u'last_credit_pull_d', u'collections_12_mths_ex_med',\n",
       "       u'mths_since_last_major_derog', u'policy_code', u'application_type',\n",
       "       u'annual_inc_joint', u'dti_joint', u'verification_status_joint',\n",
       "       u'acc_now_delinq', u'tot_coll_amt', u'tot_cur_bal', u'open_acc_6m',\n",
       "       u'open_il_6m', u'open_il_12m', u'open_il_24m', u'mths_since_rcnt_il',\n",
       "       u'total_bal_il', u'il_util', u'open_rv_12m', u'open_rv_24m',\n",
       "       u'max_bal_bc', u'all_util', u'total_rev_hi_lim', u'inq_fi',\n",
       "       u'total_cu_tl', u'inq_last_12m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname='direct_lending_club_data/lending_club_data.h5'\n",
    "df=pd.read_hdf(fname,'loandata')\n",
    "cols=df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname='direct_lending_club_data/loan.csv'\n",
    "reader=pd.read_csv(fname,chunksize=1000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "    for cc in cols.keys():\n",
    "        df[cc]=df[cc].astype(cols[cc])\n",
    "        \n",
    "    df.fillna(value=-1,inplace=True)\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('lending_club_data', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pass\n",
    "    k=k+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname='direct_lending_club_data/LoanStats3a.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    df.fillna(value=-1,inplace=True)\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('lending_club_stats', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname='direct_lending_club_data/RejectStatsA.csv'\n",
    "reader=pd.read_csv(fname,chunksize=50000)\n",
    "\n",
    "k=1\n",
    "for df in reader:\n",
    "    print k\n",
    "#     for cc in cols.keys():\n",
    "#         df[cc]=df[cc].astype(cols[cc])\n",
    "    df.fillna(value=-1,inplace=True)\n",
    "    for cc in df.columns:  \n",
    "        df.rename(columns={cc:cc.replace(' ','_').replace('(','').replace(')','').replace('\\\\','_').replace('/','_').replace('\\xef','').replace('\\xbb','').replace('\\xbf','').replace(' ','_')},\n",
    "                  inplace=True)\n",
    "    try:\n",
    "        df.to_sql('lending_club_reject', engine,flavor='mysql',if_exists='append')\n",
    "    except:\n",
    "        pdb.set_trace()\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or provide a sql query to read only select columns and rows\n",
    "sql_query=\"\"\"  \"\"\"\n",
    "df=pd.read_sql_query(sql_query,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print df.columns\n",
    "print df.dtypes\n",
    "print df.head()\n",
    "\n",
    "CREATE TABLE \"Chicago_crime_2001_present\" \n",
    "(\"Case Number\" char(15), Date date, Block char(30), IUCR char(5),\n",
    "\"Primary Type\" char(50), Description varchar, \"Location Description\" char(50), \n",
    " Arrest boolean,Domestic boolean,Beat integer,Ward float,\"FBI Code\" char(5),\n",
    " \"X Coordinate\" float,\"Y Coordinate\" float,Year integer,Latitude float,\n",
    "Longitude float,Location varchar);\n",
    "# Copy data from your CSV file to the table:\n",
    "\n",
    "# COPY zip_codes FROM '/path/to/csv/ZIP_CODES.txt' DELIMITER ',' CSV;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
